{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem set in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). Your code should run from top to bottom with no errors. Failure to do this will result in loss of points.\n",
    "\n",
    "You should not use `install.packages()` anywhere. You may assume that we have already installed all the packages needed to run your code.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\" and delete the `stop()` functions, as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"aayushap\"  # your uniqname \n",
    "COLLABORATORS = c(\"pjmerica\", \"sohumm\", \"kaspersj\")  # vector of uniqnames of your collaborators, if any\n",
    "## IMPORTANT: you must also have set your group on Canvas. This is only used as a backup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f806389838eeb4c891f9db33c2c8cda7",
     "grade": false,
     "grade_id": "cell-892bf1ae756bcb37",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(modelr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "deb835cfb55ce9af2379cd2a867580c2",
     "grade": false,
     "grade_id": "cell-f73c39701a1d2ed0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# STATS 306\n",
    "## Problem Set 10: Regression and Modeling\n",
    "Each problem is worth two points, for a total of 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d80451bfcce1911cb33389ce22f2570a",
     "grade": false,
     "grade_id": "cell-9e6d730e76d4355a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 1\n",
    "If we regress `y` on `x`, then the regression coefficient gives the average rate of change of `y` with respect to `x`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6e67f1aefa318d8cb0b2d81b78763c44",
     "grade": false,
     "grade_id": "cell-32c23065a1f25fc4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>0.844201592258372</dd>\n",
       "\t<dt>hwy</dt>\n",
       "\t\t<dd>0.683219111652059</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 0.844201592258372\n",
       "\\item[hwy] 0.683219111652059\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   0.844201592258372hwy\n",
       ":   0.683219111652059\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)         hwy \n",
       "  0.8442016   0.6832191 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm(cty ~ hwy, mpg) %>% coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4d9de03ca896ee658a0d2bec8e0a3a81",
     "grade": false,
     "grade_id": "cell-c54d1866f02177d8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "This says that if highway mileage increases by one mile per gallon, average city mileage increases by about 0.68 miles per gallon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dead62847c47af47b241111c76a43d9a",
     "grade": false,
     "grade_id": "cell-9a94060cdde7d46c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 2 x 2\n",
      "    hwy `mean(cty)`\n",
      "  <int>       <dbl>\n",
      "1    24        16.7\n",
      "2    25        17.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.641025641025639"
      ],
      "text/latex": [
       "0.641025641025639"
      ],
      "text/markdown": [
       "0.641025641025639"
      ],
      "text/plain": [
       "[1] 0.6410256"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dcity = mpg %>% filter(hwy %in% 24:25) %>% \n",
    "                group_by(hwy) %>% summarize(mean(cty)) %>% print\n",
    "diff(dcity[[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fbcef09946a1e741e79f09bb7a682c6f",
     "grade": false,
     "grade_id": "cell-e2220bfe5829bc2c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In class we saw that `log(price)` has approximately a linear relationship with `log(carat)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "286f7813a5196d461711bd5bcdb9df58",
     "grade": false,
     "grade_id": "cell-064a0ab5a5cd8379",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>8.44866072802713</dd>\n",
       "\t<dt>log(carat)</dt>\n",
       "\t\t<dd>1.6758167307252</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 8.44866072802713\n",
       "\\item[log(carat)] 1.6758167307252\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   8.44866072802713log(carat)\n",
       ":   1.6758167307252\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  log(carat) \n",
       "   8.448661    1.675817 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm(log(price) ~ log(carat), diamonds) %>% coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "306af6dc60cd35e93b35484021cdf3fb",
     "grade": false,
     "grade_id": "cell-d21ef9969df8b0b1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "What does this regression say about the relationship between __price__ (not `log(price)`) and __carat__ (not `log(carat)`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5e23ba89c5b24e1ffb03a7bfc070557f",
     "grade": true,
     "grade_id": "cell-0ad01704f1f557d6",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Price and Carat have a positive exponential relationship. As the number of carats increases, the price of the diamond increases exponentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d7371088938a94337bd4f0ee761d157a",
     "grade": false,
     "grade_id": "cell-768d9201fc2fac0c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 2\n",
    "In lecture we said that regressing `log(price)` on `log(carat)` \"removed\" the effect of size on a diamond's price, enabling us to visualize net effect of cut, color, and clarity on price by looking at the residuals of that regression.\n",
    "\n",
    "If the residuals are not affected by `log(carat)`, then intuitively they should be uncorrelated with `log(carat)`. Verify that this is true by computing the correlation between the residuals and the size predictor in this regression. Due to numerical error it will be very small but not exactly zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "49d5066f37239e686dc24bb6f0463f0f",
     "grade": true,
     "grade_id": "cell-8bff9fb6f94593da",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "-2.75587653563431e-13"
      ],
      "text/latex": [
       "-2.75587653563431e-13"
      ],
      "text/markdown": [
       "-2.75587653563431e-13"
      ],
      "text/plain": [
       "[1] -2.755877e-13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod2 = lm(log(price) ~ log(carat), diamonds)\n",
    "improveddiamonds = diamonds %>% add_residuals(mod2, \"residuals\") %>% add_predictions(mod2) %>% \n",
    "mutate(logcarat = log(carat))\n",
    "Howaretheyconnected = cor(improveddiamonds$residuals,improveddiamonds$logcarat)\n",
    "Howaretheyconnected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "79fe3546d94e143f39be61ca915efb79",
     "grade": false,
     "grade_id": "cell-2bf29ee97e2ef4e6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Explain why this implies that the predicted values are also uncorrelated with the residuals in a linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "57d4fd0793711878a9c411ab136755a1",
     "grade": true,
     "grade_id": "cell-f20b6ff093ff4e88",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "If the predicted values were correlated with the residuals, that could mean that our predictor variable log(carats) may not be exogenous and that some unaccounted for variance is not being explained by our linear model. If the predictor is does not have the same correlation with residual as the observed result, our model is misrepresenting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3aee1a25c5daab4838a50adb00a0fede",
     "grade": false,
     "grade_id": "cell-96b4568e5c3b34d3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Bootstrapping\n",
    "The standard error of a regression coefficient measures how much that estimate varies if we were to run the same data experiment many times and repeatedly re-fit a linear model. For example, suppose we get data from the following experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d54644871dd3eb5f21c24b5dc1ecfb32",
     "grade": false,
     "grade_id": "cell-363d7c35e1d725a1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "experiment = function() {\n",
    "    tibble(\n",
    "        x1 = rexp(rate = 10, n = 100),\n",
    "        x2 = rnorm(n = 100),\n",
    "        y = 3 * x1 - 2 * x2 + rnorm(n = 100, sd = .1)\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "96d932a3ff3ccca729a25e47b0eba400",
     "grade": false,
     "grade_id": "cell-84a3be38174bc4de",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "If we regress `y` on `x1` and `x2`, the standard error of `x1` coefficient in estimated to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41ffc1518432906034461a6bb2b49b6d",
     "grade": false,
     "grade_id": "cell-a7fee9140793018e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0107170161037274"
      ],
      "text/latex": [
       "0.0107170161037274"
      ],
      "text/markdown": [
       "0.0107170161037274"
      ],
      "text/plain": [
       "[1] 0.01071702"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_data = experiment()\n",
    "lm(y ~ x1 + x2, experiment_data) %>% summary %>% coef %>% .['x2', 'Std. Error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6518f6ebc755a0d9ad296a8d7fa8c474",
     "grade": false,
     "grade_id": "cell-7c5a3e88aa3e93a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We can verify that this is (approximately) correct by repeatedly running the experiment, fitting the linear model, and computing the standard error of the resulting estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "49ae176ea94787b2e704313224d7b0d1",
     "grade": false,
     "grade_id": "cell-a4693399920cae45",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0101810128953829"
      ],
      "text/latex": [
       "0.0101810128953829"
      ],
      "text/markdown": [
       "0.0101810128953829"
      ],
      "text/plain": [
       "[1] 0.01018101"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extract_coef = function(df) lm(y ~ x1 + x2, df) %>% coef %>% .[\"x2\"]\n",
    "map(1:1000, ~ experiment()) %>% map_dbl(extract_coef) %>% sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "97a393a2ae6e856285b3228b40300606",
     "grade": false,
     "grade_id": "cell-355b05d9d36d2f23",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Of course, in real life, we usually do not have the luxury of generating as many new data sets as we want; we just have a single data set. A famous idea in statistics is to use just our one data set to generate many new data sets by sampling the observations with replacement. This is called [bootstrapping][1]; starting with just one data set we \"pull ourselves up by our bootstraps\".\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Bootstrapping_(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5915c981734b6a4c7a55de756d0e2deb",
     "grade": false,
     "grade_id": "cell-2f41f47e1c4b720d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 3\n",
    "Write a function `bootstrap_df(df)` which, given a data frame containing `n` rows, returns a new data frame containing `n` rows sampled randomly _with replacement_ from `df`. (The \"with replacement\" part is important for obvious reasons.) For example, if\n",
    "```{r}\n",
    "df = tribble(\n",
    "    ~x, ~y,\n",
    "    1,   2,\n",
    "    3,   4,\n",
    "    5,   6\n",
    ")\n",
    "```\n",
    "then `bootstrap_df(df)` might return:\n",
    "\n",
    "```{r}\n",
    "  x y\n",
    "1 1 2\n",
    "2 1 2\n",
    "3 3 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "55917cb2c852711707d88774e29b6bc4",
     "grade": false,
     "grade_id": "cell-ec737ca5706fbedb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bootstrap_df = function(df) {\n",
    "    index = 1:nrow(df)\n",
    "    new_index = sample(index, replace = TRUE)\n",
    "    newboi = df[new_index,]\n",
    "    return(newboi)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "716eab63a35cdbe16cbfee68c933f08c",
     "grade": true,
     "grade_id": "cell-7ee57264e3e796af",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "bs = bootstrap_df(sim1)\n",
    "stopifnot(nrow(bs) == nrow(sim1))\n",
    "bs = bootstrap_df(tibble(x = rep(1, 100)))\n",
    "stopifnot(bs$x == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "92d8f4c79d0c72390024685427075eb5",
     "grade": false,
     "grade_id": "cell-65b7985d62b9a936",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 4\n",
    "Use `bootstrap_df` to generate 1000 bootstrap replicates from `experiment_df` defined above, and use them to verify that the standard error of the `x2` regression coefficient is again $\\approx 0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a04a3a6677942dbb570cc6d87eff7360",
     "grade": true,
     "grade_id": "cell-7743ffbe788c26c6",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.00980337304792711"
      ],
      "text/latex": [
       "0.00980337304792711"
      ],
      "text/markdown": [
       "0.00980337304792711"
      ],
      "text/plain": [
       "[1] 0.009803373"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " extract_coef = function(df) lm(y ~ x1 + x2, df) %>% coef %>% .[\"x2\"]\n",
    "map(1:1000, ~ bootstrap_df(experiment_data)) %>% map_dbl(extract_coef) %>% sd \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "42ded4976b2b36867e35cec5029cf41f",
     "grade": false,
     "grade_id": "cell-e1433195e1e94b54",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Notice that the bootstrap is very general: nothing about it is specific to linear regression. This is why it is so popular, because it lets us estimate uncertainty in more complicated models where (unlike regression) we don't have  exact formulas for the standard error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "45b455689d4e7e846420df2fdb403bcd",
     "grade": false,
     "grade_id": "cell-2dd354d2c78b7bb2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Variable selection\n",
    "In lecture we looked at a few examples of variable (a.k.a. model) selection: given a response variable, and some predictors, we studied residual plots in order to understand which predictors should be added to the model.\n",
    "\n",
    "This procedure works okay for small data sets, but quickly becomes unmanageable on larger data sets. Already with ten predictors, there are $2^{10} = 1024$ different linear models that we could fit (not including interaction terms)! So, on real data, it is usually not possible to do model selection by hand. Some sort of automated procedure is needed.\n",
    "\n",
    "------\n",
    "\n",
    "In this problem you will implement one such procedure, known as *all subsets regression*. The idea is simple: given a response variable $y$ and predictors $x_1, \\dots, x_p$, we fit all possible linear models involving $y$ and different combinations of the $x_i$. For each fitted model we record some measure of the quality of the fit. We select the model that has the highest quality score.\n",
    "\n",
    "\n",
    "If you want a more detailed description of how the algorithm should work, see the notebook [all_subsets_demo.ipynb](all_subsets_demo.ipynb) in this folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bdd7a5ed446a9e3536ad48089936c2f9",
     "grade": false,
     "grade_id": "cell-0b79b758f5e4ec91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 5\n",
    "Write a function `power_set(v)` which, given a vector `v`, returns a list of all possible subsets of `v` (including the empty set). For example:\n",
    "\n",
    "```{r}\n",
    "> str(power_set(1:3))\n",
    "List of 8\n",
    " $ : int [1:3] 1 2 3\n",
    " $ : int [1:2] 1 2\n",
    " $ : int [1:2] 1 3\n",
    " $ : int 1\n",
    " $ : int [1:2] 2 3\n",
    " $ : int 2\n",
    " $ : int 3\n",
    " $ : NULL\n",
    "> str(power_set(list('a', 'b', 'c')))\n",
    "List of 8\n",
    " $ : chr [1:3] \"a\" \"b\" \"c\"\n",
    " $ : chr [1:2] \"a\" \"b\"\n",
    " $ : chr [1:2] \"a\" \"c\"\n",
    " $ : chr \"a\"\n",
    " $ : chr [1:2] \"b\" \"c\"\n",
    " $ : chr \"b\"\n",
    " $ : chr \"c\"\n",
    " $ : NULL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6349716ec05446ec8a9dc201a989cbe7",
     "grade": false,
     "grade_id": "cell-1505631f22f24540",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "power_set = function(v) {\n",
    "    result = list()\n",
    "    count = 1\n",
    "    for(i in 1:length(v)){\n",
    "        set = combn(v,i,simplify = TRUE)\n",
    "            \n",
    "            for(j in 1:ncol(set)){\n",
    "                result[[count]] = unlist(set[,j])\n",
    "                count = count + 1\n",
    "                }\n",
    "    }\n",
    "    result[count] = list(NULL)\n",
    "    return(result)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c41312add0d22bf984582e82e732bf12",
     "grade": true,
     "grade_id": "cell-7fa379507ae80ffd",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stopifnot(setequal(\n",
    "    power_set(list('a', 'b')),\n",
    "    list(c('a', 'b'), c('a'), c('b'), NULL)\n",
    "    ))\n",
    "stopifnot(setequal(\n",
    "    power_set(1:3),\n",
    "    list(1:3, 1:2, 2:3, c(1, 3), 1, 2, 3, NULL)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d678ac7339442687632ac95fae76b9e2",
     "grade": false,
     "grade_id": "cell-73f042329e24d260",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 6\n",
    "Use the function you defined in problem 4 to create a function `all_subdfs(df)`. Given a data frame `df`, `all_subdfs(df)` returns a new list of dataframes. Each entry in the list contains a subset of the columns in `df`, and there are as many entries as there are subsets of the columns (i.e., $2^p$ if there are $p$ columns.) \n",
    "\n",
    "For example:\n",
    "```{r}\n",
    "> all_subdfs(tibble(a=1:3, b=2:4, c=c('a','b','c'))) %>% str\n",
    "List of 8\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  3 variables:\n",
    "  ..$ a: int [1:3] 1 2 3\n",
    "  ..$ b: int [1:3] 2 3 4\n",
    "  ..$ c: chr [1:3] \"a\" \"b\" \"c\"\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  2 variables:\n",
    "  ..$ a: int [1:3] 1 2 3\n",
    "  ..$ b: int [1:3] 2 3 4\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  2 variables:\n",
    "  ..$ a: int [1:3] 1 2 3\n",
    "  ..$ c: chr [1:3] \"a\" \"b\" \"c\"\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  1 variable:\n",
    "  ..$ a: int [1:3] 1 2 3\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  2 variables:\n",
    "  ..$ b: int [1:3] 2 3 4\n",
    "  ..$ c: chr [1:3] \"a\" \"b\" \"c\"\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  1 variable:\n",
    "  ..$ b: int [1:3] 2 3 4\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  1 variable:\n",
    "  ..$ c: chr [1:3] \"a\" \"b\" \"c\"\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  0 variables\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "87a92c2af0c3264c17854cf846837dab",
     "grade": false,
     "grade_id": "cell-5b2c3849fa337c1a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "all_subdfs = function(df) {\n",
    "   count = colnames(df)\n",
    "   powerset = power_set(count)\n",
    "   result = list()\n",
    "        for(i in 1:(length(powerset)-1)){\n",
    "            result[[i]] = df %>%  select(powerset[[i]])\n",
    "            }\n",
    "    result[[length(powerset)]] = df %>% select()\n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b5f7744a97396a303ada444d27d1c7bc",
     "grade": true,
     "grade_id": "cell-ce5e4b5dcb638182",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stopifnot(setequal(\n",
    "    all_subdfs(tibble(a=1:3, b=2:4)),\n",
    "    list(\n",
    "        tibble(a=1:3),\n",
    "        tibble(b=2:4),\n",
    "        tibble(a=1:3, b=2:4),\n",
    "        tibble()\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b73328a8bf0af4476326d440c708411f",
     "grade": false,
     "grade_id": "cell-329dbbe4690114ea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 7\n",
    "Use the function you implemented in problem 5 to write a function `all_subsets_reg(df, qual)` which takes a data frame `df` and a function `qual` and implements all-subsets regression. The function `qual(mod)` takes as input a fitted model, and returns a quality score; higher scores are better. You may assume that the first column of `df` is the response variable and is named `y`; the remaining columns of `df` are potential predictors and can have arbitrary names. Your model should always include an intercept term.\n",
    "\n",
    "The function should return a vector containing the names of the predictors that were selected under the best model. For example, if `df` is a tibble with four columns `y`, `x1`, `x2` and `x3`, and \n",
    "the algorithm selects `y ~ x1 + x3` as the best model, the `all_subsets(df, qual)` should return the vector `c(\"x1\", \"x3\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ebcb2ddf80879e74c2f3a87be9962a30",
     "grade": false,
     "grade_id": "cell-1980efd69057697c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "all_subsets_reg = function(df, qual) {\n",
    "    # YOUR CODE HERE\n",
    "    stop()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "65847e71dc67d46383b52b4730ac9e33",
     "grade": false,
     "grade_id": "cell-be947bed0bea73d6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The measure of model quality we will use is [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion). You don't need to understand how AIC works, but you should know that lower scores of AIC indicate a better model fit. Hence, we define our quality function to be:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0da31758407c1a4b3263343be17fe145",
     "grade": false,
     "grade_id": "cell-9b668d5601dfeb61",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "qual_aic = function(mdl) -AIC(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "df7737e1d9014866f92499abe2356776",
     "grade": true,
     "grade_id": "cell-c80326a3ca3e6b3a",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "zero <- vector(\"character\", 0)\n",
    "# if there are no predictors, return empty vector\n",
    "stopifnot(all.equal(all_subsets_reg(tibble(y = 1:10), qual_aic), \n",
    "                    zero))\n",
    "# x perfectly predicts y, so of course we include it\n",
    "stopifnot(all.equal(all_subsets_reg(tibble(y = 1:10, x = y), qual_aic), 'x'))\n",
    "# x2 is nearly co-linear with x1, so we do not include it.\n",
    "stopifnot(setequal(all_subsets_reg(tibble(y = 1:10, \n",
    "                                          x1 = y, \n",
    "                                          x2 = x1 + rnorm(n = 10)),\n",
    "                                   qual_aic),\n",
    "                                   'x1'))\n",
    "# if intercept-only model is selected, again return NULL\n",
    "stopifnot(all.equal(\n",
    "    all_subsets_reg(tibble(y = 1:10, x = rnorm(n = 10)), qual_aic),\n",
    "    zero\n",
    "))\n",
    "# modelr data\n",
    "stopifnot(setequal(all_subsets_reg(select(sim4, y, everything()), qual_aic), \n",
    "                   c(\"x1\", \"x2\")))\n",
    "# iris data\n",
    "data(iris)\n",
    "stopifnot(setequal(all_subsets_reg(iris, qual_aic), \n",
    "                   c(\"Sepal.Width\", \"Petal.Length\", \"Petal.Width\", \"Species\")\n",
    "                   )\n",
    "          )\n",
    "# diamonds data are too big, take subset\n",
    "df = slice(diamonds, 1:1000) %>% rename(ynew=y) %>% select(price, everything())\n",
    "stopifnot(setequal(all_subsets_reg(df, qual_aic), \n",
    "                   c(\"carat\", \"cut\", \"color\", \"clarity\", \"depth\", \n",
    "                     \"table\", \"ynew\", \"z\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dafe561e832ba3dbef7fdd7186c533f1",
     "grade": false,
     "grade_id": "cell-bbc441db6d783e79",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 8\n",
    "Suppose that instead of AIC we had chosen $R^2$ as our measure of model quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dc16559a935ed1e1976f9f0c9d8f2998",
     "grade": false,
     "grade_id": "cell-7f58678018fad0f9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "qual_R2 = function(mdl) summary(mdl)$r.squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8f4da5541c72f9c00bb9dcd2a7c43def",
     "grade": false,
     "grade_id": "cell-bcac1c9dd09fb752",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Try running `all_subsets_reg(df, qual_R2)` for a few data sets. You should notice a pattern in terms of the variables that get selected. Explain why this pattern occurs. Is $R^2$ appropriate to use for model selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dd48009a4d132d22eb3d12660dfb1487",
     "grade": true,
     "grade_id": "cell-1db1d481c975b22f",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "R^2 is not appropriate for model selection because it only allows you to determine whether your model is good at explaining the observed data. AIC, on the other hand, provides an idea of how well your model will predict at NEW data sets. Because AIC prefer simple models, we should see a pattern similar variables being selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "839562e725314de218152fa2d87e697f",
     "grade": false,
     "grade_id": "cell-5c041b7bf1baa08f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Overfitting\n",
    "The previous problem studied variable selection. Why is variable selection necessary at all? Shouldn't we use all the available data, rather than adding only a subset of the predictors to our model? \n",
    "\n",
    "One argument for using fewer variables is parsimony: as we discussed in lecture, simpler models are more interpretable. However, even if we do not care about interpretability, there is another reason for preferring less complex models. In this problem, we will see that reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "59032e15739b05aef3861f7da12dfa0c",
     "grade": false,
     "grade_id": "cell-3f3dd1c588a3156a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 9\n",
    "Write a function `split_data(df, p)` which, given a data frame `df` and a number $p \\in (0, 1)$, returns a list with two named elements, `train` and `test`. The function will randomly sample  (without replacement) $100 \\times p \\%$ of the rows (rounded to the nearest integer) from `df` and assign them to `train`. The remaining rows will be stored in `test`. For example, if `df` is a tibble with 100 rows and two columns then\n",
    "```{r}\n",
    "> split_data(df, p)\n",
    "$train\n",
    "# A tibble: 50 x 2\n",
    "<...>\n",
    "$test\n",
    "# A tibble: 50 x 2\n",
    "<...>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7322aaa9e2d0cac8e6f5aafaaefca278",
     "grade": false,
     "grade_id": "cell-8ead8e2b94131a9a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "split_data = function(df, p) {\n",
    "    trainer = sample(1:nrow(df), size = round(p * nrow(df)))\n",
    "    train = df[trainer,]\n",
    "    test = df[-trainer,]\n",
    "    v = list(train=train, test=test)\n",
    "    return(v)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "198ca74a0d4c3ae8f497e48938222f66",
     "grade": true,
     "grade_id": "cell-09760af7622a6f33",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stopifnot(nrow(split_data(sim1, .5)$train) == 15)\n",
    "stopifnot(nrow(split_data(sim1, .5)$test) == 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d3b7303b653624ae0ff368d032df0325",
     "grade": false,
     "grade_id": "cell-17927acd0860efdc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 10\n",
    "Write a function `ssr(df, mod)` which, given a data frame `df` and a model `mod`, returns the sum of squared residuals obtained by applying `mod` to `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "017367a39baf85720375dbcb5d1ff801",
     "grade": false,
     "grade_id": "cell-40e7f95fff907be2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ssr = function(df, mod) {\n",
    "    resid = c()\n",
    "    for (i in 1:length(df))\n",
    "    resid[i] = sum((df[i] - mod[i])^2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "53a8576c212d0c5e64f8b4f2e501560f",
     "grade": true,
     "grade_id": "cell-9d04eec35f808a2b",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stopifnot(near(ssr(sim1, lm(y ~ x, sim1)), 135.8746, tol=1e-1))\n",
    "stopifnot(near(ssr(sim4, lm(y ~ x1 + x2, sim4)), 1322.714, tol=1e-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "733ba4b0e3d9da70aba83f2a5162bc75",
     "grade": false,
     "grade_id": "cell-d32c8fc6a29cbaf5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will split the `diamonds` into two halves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "df = split_data(diamonds, .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9f4c60a48092d27ad3355ffe69532b3e",
     "grade": false,
     "grade_id": "cell-995fb1882b5d63b0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "On the training data we will fit two models. The first is `log(price) ~ log(carat)` which we saw in lecture. The second, `log(price) ~ log(carat) + .^2`, contains hundreds more interaction terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3530743cc0a099546d6836631a57599c",
     "grade": false,
     "grade_id": "cell-8ceffc0525650c41",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in df$train: object of type 'closure' is not subsettable\n",
     "output_type": "error",
     "traceback": [
      "Error in df$train: object of type 'closure' is not subsettable\nTraceback:\n",
      "1. lm(log(price) ~ log(carat), df$train)",
      "2. eval(mf, parent.frame())",
      "3. eval(mf, parent.frame())",
      "4. stats::model.frame(formula = log(price) ~ log(carat), data = df$train, \n .     drop.unused.levels = TRUE)",
      "5. model.frame.default(formula = log(price) ~ log(carat), data = df$train, \n .     drop.unused.levels = TRUE)",
      "6. is.data.frame(data)"
     ]
    }
   ],
   "source": [
    "mod1 = lm(log(price) ~ log(carat), df$train)\n",
    "mod2 = lm(log(price) ~ log(carat) + .^2, df$train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c31ca59945e42faf19eb2055118c4159",
     "grade": false,
     "grade_id": "cell-7042b0208600dba3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "`mod2` is a much better predictor of `log(price)` on the training data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f2bde6c2391a7289d52800dcda132e01",
     "grade": false,
     "grade_id": "cell-4bfaf456e139d2ed",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in ssr(df$train, mod1): could not find function \"ssr\"\n",
     "output_type": "error",
     "traceback": [
      "Error in ssr(df$train, mod1): could not find function \"ssr\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "ssr(df$train, mod1)\n",
    "ssr(df$train, mod2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19c681fb9ef95453b0f6f061869e95bf",
     "grade": false,
     "grade_id": "cell-a12ff1f50f4de43a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "However, `mod2` does much *worse* if we compare them on the test data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "402d47cdc56bf949f9503d58b08844cb",
     "grade": false,
     "grade_id": "cell-3a3bedee86cd3cf8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ssr(df$test, mod1)\n",
    "ssr(df$test, mod2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d12c41201f04bc89f12039f064e354f9",
     "grade": false,
     "grade_id": "cell-7f0be1469c754fc0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "This is called [overfitting](https://en.wikipedia.org/wiki/Overfitting). `mod2` has so many extra predictors that it can fit not only the actual patterns which are present in `df$train`, but also the random noise in that data. Since the noise is different in `df$test`, `mod2` does a worse job of predicting \"out of sample\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
